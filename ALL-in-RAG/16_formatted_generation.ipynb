{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2832ae9",
   "metadata": {},
   "source": [
    "# 格式化生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ac49a",
   "metadata": {},
   "source": [
    "## 使用场景\n",
    "\n",
    "- RAG 驱动的电商客服：当用户询问“推荐几款适合程序员的键盘”时，我们希望 LLM 返回一个包含产品名称、价格、特性和购买链接的 JSON 列表，而不是一段描述性文字，以便前端直接渲染成商品卡片。\n",
    "\n",
    "- 自然语言转 API 调用：用户说“帮我查一下明天从上海到北京的航班”，系统需要将这句话解析成一个结构化的 API 请求，如 {\"departure\": \"上海\", \"destination\": \"北京\", \"date\": \"2025-07-18\"}。\n",
    "\n",
    "- 数据自动提取：从一篇新闻文章中，自动抽取出事件、时间、地点、涉及人物等关键信息，并以结构化形式存入数据库。\n",
    "\n",
    "在这些场景中，格式化生成是连接 LLM 的自然语言理解能力和下游应用程序的程序化逻辑之间的关键。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e983b14",
   "metadata": {},
   "source": [
    "## 实现方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa28f4",
   "metadata": {},
   "source": [
    "### LangChain 中\n",
    "\n",
    "LangChain 提供了一个强大的组件——OutputParsers（输出解析器），专门用于处理 LLM 的输出。\n",
    "\n",
    "- 提供格式指令：在发送给 LLM 的提示（Prompt）中，自动注入一段关于如何格式化输出的指令。\n",
    "\n",
    "- 解析模型输出：接收 LLM 返回的纯文本字符串，并将其解析成预期的结构化数据（如 Python 对象）。\n",
    "\n",
    "详情见：https://docs.langchain.com/oss/python/langchain/structured-output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ebc1e4",
   "metadata": {},
   "source": [
    "### LlamaIndex 中\n",
    "\n",
    "LlamaIndex 的输出解析与生成过程紧密结合。\n",
    "\n",
    "- 响应合成（Response Synthesis）：，检索器召回一系列相关的文本块（Nodes）后，响应合成器接收这些文本块和原始查询，并以一种更智能的方式将它们呈现给 LLM 以生成最终答案。\n",
    "\n",
    "    - 它可以逐块处理信息并迭代地优化答案（refine 模式），或者将尽可能多的文本块压缩进单次 LLM 调用中（compact 模式）。这个阶段的默认目标是生成一段高质量的文本回答。\n",
    "\n",
    "- 结构化输出（Structured Output）： \n",
    "\n",
    "    1. 定义 Schema：定义一个 Pydantic 模型，明确所需输出的数据结构、字段和类型。\n",
    "   \n",
    "    2. 引导生成：LlamaIndex 会将这个 Pydantic 模型转换成 LLM 能理解的格式指令。\n",
    "   \n",
    "    3. 解析验证：LM 返回的输出会被自动解析并用 Pydantic 模型进行验证，确保其类型和结构完全正确，最终返回一个 Pydantic 对象实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c8629",
   "metadata": {},
   "source": [
    "### 不依赖框架的简单实现思路\n",
    "\n",
    "通过提示工程给出清晰、明确的指令和示例。\n",
    "\n",
    "- 明确要求 JSON 格式：在提示中直接、强硬地要求模型“必须返回一个 JSON 对象”、“不要包含任何解释性文字，只返回 JSON”。\n",
    "\n",
    "- 提供 JSON Schema：在提示中给出你想要的 JSON 对象的模式（Schema），描述每个键的含义和数据类型。\n",
    "\n",
    "- 提供 few-shot 示例：给出 1-2 个“用户输入 -> 期望的 JSON 输出”的完整示例，让模型学习输出的格式和风格。\n",
    "\n",
    "- 使用语法约束：对于一些本地部署的开源模型（如通过 llama.cpp 运行的模型），可以使用 GBNF (GGML BNF) 等语法文件来强制约束模型的输出，确保其生成的每一个 token 都严格符合预定义的 JSON 语法。**这是最严格也是最可靠的非 Function Calling 方法。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f37e2",
   "metadata": {},
   "source": [
    "## Function Calling\n",
    "\n",
    "Function Calling（或称 Tool Calling）本质是一个多轮对话流程，让模型、代码和外部工具（如 API）协同工作。\n",
    "\n",
    "相比于单纯通过提示工程“请求”模型输出 JSON，Function Calling 的优势在于：\n",
    "\n",
    "- 可靠性更高：这是**模型原生支持的能力**，相比于解析可能格式不稳定的纯文本输出，这种方式得到的结构化数据更稳定、更精确。\n",
    "\n",
    "- 意图识别：它不仅仅是格式化输出，更包含了“意图到函数的映射”。模型能根据用户问题主动选择最合适的工具。\n",
    "\n",
    "- 与外部世界交互：它是构建能执行实际任务的 AI 代理（Agent）的核心基础，让 LLM 可以查询数据库、调用 API、控制智能家居等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61976e",
   "metadata": {},
   "source": [
    "### 工作流程\n",
    "\n",
    "1. 定义工具：首先，在代码中以特定格式（通常是 JSON Schema）定义好可用的工具，包括工具的名称、功能描述、以及需要的参数。\n",
    "\n",
    "2. 用户提问：用户发起一个需要调用工具才能回答的请求。\n",
    "\n",
    "3. 模型决策：模型接收到请求后，分析用户的意图，并匹配最合适的工具。\n",
    "\n",
    "    - 它不会直接回答，而是返回一个包含 tool_calls 的特殊响应。\n",
    "    - 这个响应相当于一个指令：“请调用某某工具，并使用这些参数”。\n",
    "\n",
    "4. 代码执行：应用接收到这个指令，解析出工具名称和参数，然后在代码层面实际执行这个工具（例如，调用一个真实的天气 API）。\n",
    "\n",
    "5. 结果反馈：将工具的执行结果（例如，从 API 获取的真实天气数据）包装成一个 role 为 tool 的消息，再次发送给模型。\n",
    "   \n",
    "6. 最终生成：模型接收到工具的执行结果后，结合原始问题和工具返回的信息，生成最终的、自然的语言回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化大模型\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，用于发送消息并获取模型的响应\n",
    "def send_messages(messages, tools=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # 让模型自主决定是否调用工具\n",
    "    )\n",
    "    return response.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义工具\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"获取指定地点的天气信息\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"城市和省份，例如：杭州市, 浙江省\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa3266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User> 杭州今天天气怎么样？\n",
      "\n",
      "--- 模型发起了工具调用 ---\n",
      "工具名称: get_weather\n",
      "工具参数: {\"location\": \"杭州市, 浙江省\"}\n",
      "--- 执行工具并返回结果 ---\n",
      "工具执行结果: 24℃，晴朗\n",
      "\n",
      "--- 将工具结果返回给模型，获取最终答案 ---\n",
      "Model> 根据查询结果，杭州今天天气很好：\n",
      "\n",
      "- **温度**：24℃\n",
      "- **天气状况**：晴朗\n",
      "\n",
      "今天是个适合外出活动的好天气！\n"
     ]
    }
   ],
   "source": [
    "# 用户提问，模型决策调用工具\n",
    "messages = [{\"role\": \"user\", \"content\": \"杭州今天天气怎么样？\"}]\n",
    "print(f\"User> {messages[0]['content']}\\n\")\n",
    "message = send_messages(messages, tools=tools)\n",
    "\n",
    "# 执行工具，并将结果返回模型\n",
    "if message.tool_calls:\n",
    "    print(\"--- 模型发起了工具调用 ---\")\n",
    "    tool_call = message.tool_calls[0]\n",
    "    function_info = tool_call.function\n",
    "    print(f\"工具名称: {function_info.name}\")\n",
    "    print(f\"工具参数: {function_info.arguments}\")\n",
    "\n",
    "    # 将模型的回复（包含工具调用请求）添加到消息历史中\n",
    "    messages.append(message)\n",
    "\n",
    "    # 模拟执行工具\n",
    "    tool_output = \"24℃，晴朗\"\n",
    "    print(f\"--- 执行工具并返回结果 ---\")\n",
    "    print(f\"工具执行结果: {tool_output}\\n\")\n",
    "\n",
    "    # 将工具的执行结果作为一个新的消息添加到历史中\n",
    "    messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": tool_output})\n",
    "\n",
    "    # 第二次调用：将工具结果返回给模型，获取最终回答\n",
    "    print(\"--- 将工具结果返回给模型，获取最终答案 ---\")\n",
    "    final_message = send_messages(messages, tools=tools)\n",
    "    print(f\"Model> {final_message.content}\")\n",
    "else:\n",
    "    # 如果模型没有调用工具，直接打印其回答\n",
    "    print(f\"Model> {message.content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
