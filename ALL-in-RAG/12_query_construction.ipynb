{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01d45e6",
   "metadata": {},
   "source": [
    "# 查询构建（Query Construction）\n",
    "\n",
    "在实际应用中，我们常常需要处理更加复杂和多样化的数据，包括结构化数据（如SQL数据库）、半结构化数据（如带有元数据的文档）以及图数据。\n",
    "\n",
    "用户的查询也可能不仅仅是简单的语义匹配，而是包含复杂的过滤条件、聚合操作或关系查询。\n",
    "\n",
    "查询构建利用大语言模型（LLM）的强大理解能力，将用户的自然语言查询“翻译”成针对特定数据源的结构化查询语言或带有过滤条件的请求。\n",
    "\n",
    "使RAG系统能够无缝地连接和利用各种类型的数据，从而极大地扩展了其应用场景和能力。\n",
    "\n",
    "![](images/4_2_1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3714ddf",
   "metadata": {},
   "source": [
    "## 文本到元数据过滤器\n",
    "\n",
    "构建向量索引时，常常会为文档块（Chunks）附加元数据（Metadata），例如文档来源、发布日期、作者、章节、类别等。\n",
    "\n",
    "这些元数据为我们提供了在语义搜索之外进行精确过滤的可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762cf515",
   "metadata": {},
   "source": [
    "自查询检索器（Self-Query Retriever） 是LangChain中实现这一功能的核心组件。\n",
    "\n",
    "工作流程：\n",
    "\n",
    "1. 定义元数据结构：向LLM清晰地描述文档内容和每个元数据字段的含义及类型。\n",
    "\n",
    "2. 查询解析：自查询检索器会调用LLM，将用户输入的查询分解为两部分：\n",
    "\n",
    "    - 查询字符串（Query String）：用于进行语义搜索的部分。\n",
    "\n",
    "    - 元数据过滤器（Metadata Filter）：从查询中提取出的结构化过滤条件。\n",
    "\n",
    "3. 执行查询：检索器将解析出的查询字符串和元数据过滤器发送给向量数据库，执行一次同时包含语义搜索和元数据过滤的查询。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62d338",
   "metadata": {},
   "source": [
    "例如，对于查询“关于2022年发布的机器学习的论文”，自查询检索器会将其解析为：\n",
    "\n",
    "- 查询字符串: \"机器学习的论文\"\n",
    "\n",
    "- 元数据过滤器: year == 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2033a54",
   "metadata": {},
   "source": [
    "## 示例\n",
    "\n",
    "以B站视频为例来看看如何使用 SelfQueryRetriever。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596ad49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\env\\langchain1.0\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 初始化视频数据\n",
    "from langchain_community.document_loaders import BiliBiliLoader\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "video_urls = [\n",
    "    \"https://www.bilibili.com/video/BV1Bo4y1A7FU\", \n",
    "    \"https://www.bilibili.com/video/BV1ug4y157xA\",\n",
    "    \"https://www.bilibili.com/video/BV1yh411V7ge\",\n",
    "]\n",
    "\n",
    "bili = []\n",
    "try:\n",
    "    # 使用 BiliBiliLoader 加载B站视频的文档和元数据\n",
    "    loader = BiliBiliLoader(video_urls=video_urls)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    for doc in docs:\n",
    "        original = doc.metadata\n",
    "        \n",
    "        # 手动提取需要的元数据字段\n",
    "        metadata = {\n",
    "            'title': original.get('title', '未知标题'),\n",
    "            'author': original.get('owner', {}).get('name', '未知作者'),\n",
    "            'source': original.get('bvid', '未知ID'),\n",
    "            'view_count': original.get('stat', {}).get('view', 0),\n",
    "            'length': original.get('duration', 0),\n",
    "        }\n",
    "        \n",
    "        # 构建新 metadata 字典\n",
    "        doc.metadata = metadata\n",
    "        bili.append(doc)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"加载BiliBili视频失败: {str(e)}\")\n",
    "\n",
    "if not bili:\n",
    "    print(\"没有成功加载任何视频，程序退出\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85446092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: models/bge/bge-small-zh-v1.5\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# 创建向量存储\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"models/bge/bge-small-zh-v1.5\")\n",
    "# 将处理好的文档和元数据存入 Chroma 向量数据库中\n",
    "vectorstore = Chroma.from_documents(bili, embed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47546dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置元数据字段信息\n",
    "# LLM 将依赖这份描述来理解如何处理用户的查询\n",
    "from langchain_classic.chains.query_constructor.schema import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"视频标题（字符串）\",\n",
    "        type=\"string\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author\",\n",
    "        description=\"视频作者（字符串）\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"view_count\",\n",
    "        description=\"视频观看次数（整数）\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"length\",\n",
    "        description=\"视频长度，以秒为单位的整数\",\n",
    "        type=\"integer\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f73c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 LLM\n",
    "from langchain_deepseek import ChatDeepSeek \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\", \n",
    "    temperature=0, \n",
    "    api_key=os.getenv(\"Deepseek_API_Key\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0dd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 SelfQueryRetriever\n",
    "from langchain_classic.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=\"记录视频标题、作者、观看次数等信息的视频元数据\",\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    enable_limit=True,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809fbfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 查询: '时间最短的视频' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain_classic.retrievers.self_query.base:Generated Query: query=' ' filter=None limit=1\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标题: 《吴恩达 x OpenAI Prompt课程》【专业翻译，配套代码笔记】02.Prompt 的构建原则\n",
      "作者: 二次元的Datawhale\n",
      "观看次数: 19439\n",
      "时长: 1063秒\n",
      "==================================================\n",
      "\n",
      "--- 查询: '时长大于600秒的视频' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_classic.retrievers.self_query.base:Generated Query: query=' ' filter=Comparison(comparator=<Comparator.GT: 'gt'>, attribute='length', value=600) limit=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标题: 《吴恩达 x OpenAI Prompt课程》【专业翻译，配套代码笔记】02.Prompt 的构建原则\n",
      "作者: 二次元的Datawhale\n",
      "观看次数: 19439\n",
      "时长: 1063秒\n",
      "==================================================\n",
      "标题: 《吴恩达 x OpenAI Prompt课程》【专业翻译，配套代码笔记】03.Prompt如何迭代优化\n",
      "作者: 二次元的Datawhale\n",
      "观看次数: 7355\n",
      "时长: 806秒\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 测试 SelfQueryRetriever\n",
    "\n",
    "queries = [\n",
    "    \"时间最短的视频\",\n",
    "    \"时长大于600秒的视频\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n--- 查询: '{query}' ---\")\n",
    "    results = retriever.invoke(query)\n",
    "    if results:\n",
    "        for doc in results:\n",
    "            title = doc.metadata.get('title', '未知标题')\n",
    "            author = doc.metadata.get('author', '未知作者')\n",
    "            view_count = doc.metadata.get('view_count', '未知')\n",
    "            length = doc.metadata.get('length', '未知')\n",
    "            print(f\"标题: {title}\")\n",
    "            print(f\"作者: {author}\")\n",
    "            print(f\"观看次数: {view_count}\")\n",
    "            print(f\"时长: {length}秒\")\n",
    "            print(\"=\"*50)\n",
    "    else:\n",
    "        print(\"未找到匹配的视频\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca01167",
   "metadata": {},
   "source": [
    "## 文本到Cypher\n",
    "\n",
    "Cypher 是图数据库（如 Neo4j）中最常用的查询语言，其地位类似于 SQL 之于关系数据库。\n",
    "\n",
    "与“文本到元数据过滤器”类似，“文本到Cypher”技术利用大语言模型（LLM）将用户的自然语言问题直接翻译成一句精准的 Cypher 查询语句。\n",
    "\n",
    "LangChain 提供了相应的工具链（如 GraphCypherQAChain），其工作流程通常是：\n",
    "\n",
    "1. 接收用户的自然语言问题。\n",
    "\n",
    "2. LLM 根据预先提供的 Schema，将问题转换为 Cypher 查询。\n",
    "\n",
    "3. 在图数据库上执行该查询，获取精确的结构化数据。\n",
    "\n",
    "4. 将查询结果再次交由 LLM，生成通顺的自然语言答案。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
