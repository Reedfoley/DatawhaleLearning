{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deddf3de",
   "metadata": {},
   "source": [
    "# 混合检索\n",
    "\n",
    "混合检索同时利用稀疏向量的关键词精确匹配能力和密集向量的语义理解能力，以克服单一向量检索的局限性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213b549",
   "metadata": {},
   "source": [
    "## 稀疏向量 vs 密集向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea3f21",
   "metadata": {},
   "source": [
    "### 稀疏向量\n",
    "\n",
    "稀疏向量采用精准的“词袋”匹配模型，将文档视为一堆词的集合，不考虑其顺序和语法，其中向量的每一个维度都直接对应一个具体的词，非零值则代表该词在文档中的重要性（权重）。\n",
    "\n",
    "这种方法的优点是可解释性极强（每个维度都代表一个确切的词），无需训练，能够实现关键词的精确匹配。\n",
    "\n",
    "主要缺点是无法理解语义，例如它无法识别“汽车”和“轿车”是同义词，存在“词汇鸿沟”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b4b94",
   "metadata": {},
   "source": [
    "稀疏向量的核心思想是只存储非零值。\n",
    "\n",
    "例如，一个包含5万个词的词汇表中，“西红柿”在第88位，“炒”在第666位，“蛋”在第999位，它们的BM25权重分别是1.2、0.8、1.5。\n",
    "\n",
    "可表示为："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8129257",
   "metadata": {},
   "source": [
    "- 键值对：将非零元素的索引作为键，值作为值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895551c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'88': 1.2, '666': 0.8, '999': 1.5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"88\": 1.2,\n",
    "    \"666\": 0.8,\n",
    "    \"999\": 1.5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a63b13",
   "metadata": {},
   "source": [
    "- 坐标列表：用一个元组 (维度, [索引列表], [值列表]) 来表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6d0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, [88, 666, 999], [1.2, 0.8, 1.5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(50000, [88, 666, 999], [1.2, 0.8, 1.5])  # 在 SciPy 等科学计算库中非常常见\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5bd13",
   "metadata": {},
   "source": [
    "尽管这两种格式都清晰地记录了文档的关键信息。\n",
    "\n",
    "但当我们搜索“番茄炒鸡蛋”时，由于“番茄”和“西红柿”是不同的词条（索引不同），模型将无法理解它们的语义相似性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70ddb5",
   "metadata": {},
   "source": [
    "### 密集向量\n",
    "\n",
    "也常被称为“语义向量”，是通过深度学习模型学习到的数据（如文本、图像）的低维、稠密的浮点数表示。\n",
    "\n",
    "主要优点是能够理解同义词、近义词和上下文关系，泛化能力强，在语义搜索任务中表现卓越。缺点是可解释性差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ede31",
   "metadata": {},
   "source": [
    "与稀疏向量不同，密集向量的所有维度都有值，因此使用数组 [] 来表示是最直接的方式。\n",
    "\n",
    "一个预训练好的语义模型在读取“西红柿炒蛋”后，会输出一个低维的密集向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba5eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.89, -0.12, 0.77, Ellipsis, -0.45]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.89, -0.12, 0.77, ..., -0.45] # 一个低维（比如1024维）的浮点数向量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56c731",
   "metadata": {},
   "source": [
    "这个向量本身难以解读，但它在语义空间中的位置可能与“番茄鸡蛋面”、“洋葱炒鸡蛋”等菜肴的向量非常接近。\n",
    "\n",
    "因为模型理解了它们共享“鸡蛋类菜肴”、“家常菜”、“酸甜口味”等核心概念。\n",
    "\n",
    "因此，当我们搜索“蛋白质丰富的家常菜”时，即使查询中没有出现任何原文关键词，密集向量也很有可能成功匹配到这份菜谱。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bf5e2",
   "metadata": {},
   "source": [
    "## 混合检索\n",
    "\n",
    "混合检索主要是解决单一检索技术的局限性。\n",
    "\n",
    "例如，关键词检索无法理解语义，而向量检索则可能忽略掉必须精确匹配的关键词。\n",
    "\n",
    "同时利用稀疏向量的精确性和密集向量的泛化性，以应对复杂多变的搜索需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81bf707",
   "metadata": {},
   "source": [
    "### 技术原理与融合方法\n",
    "\n",
    "混合检索通常并行执行两种检索算法，然后将两组异构的结果集融合成一个统一的排序列表。\n",
    "\n",
    "以下是两种主流的融合策略："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a56856",
   "metadata": {},
   "source": [
    "#### 倒数排序融合 (Reciprocal Rank Fusion, RRF)\n",
    "\n",
    "RRF 考虑的是每个文档在各自结果集中的排名。\n",
    "\n",
    "具体来说，一个文档在不同检索系统中的排名越靠前，它的最终得分就越高。\n",
    "\n",
    "公式为：\n",
    "\n",
    "$$\n",
    "RRF_{score}(d) = \\sum_{i=1}^{k} \\frac{1}{rank_i(d) + c}\n",
    "$$\n",
    "\n",
    "- $d$: 待评分的文档。\n",
    "\n",
    "- $k$：使用的检索系统的数量（这里是2，即稀疏向量检索和密集向量检索）\n",
    "\n",
    "- $rank_i(d)$：文档 $d$ 在第 $i$ 个检索系统中的排名。\n",
    "\n",
    "- $c$：一个小的常量（通常取 60），用于降低排名靠后文档的权重，避免它们对结果产生过大影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb36c0",
   "metadata": {},
   "source": [
    "#### 加权线性组合\n",
    "\n",
    "先将不同检索系统的得分进行归一化（例如，统一到 0-1 区间），然后通过一个权重参数 α 来进行线性组合。\n",
    "\n",
    "$$ Hybrid_{score} = \\alpha \\cdot Dense_{score} + (1 - \\alpha) \\cdot Sparse_{score} $$\n",
    "\n",
    "通过调整 α 的值，可以灵活地控制语义相似性与关键词匹配在最终排序中的贡献比例。\n",
    "\n",
    "例如，在电商搜索中，可以调高关键词的权重；而在智能问答中，则可以侧重于语义。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff4f16",
   "metadata": {},
   "source": [
    "### 混合检索的优势和局限\n",
    "\n",
    "**优势：**\n",
    "\n",
    "- 召回率与准确率高：能同时捕获关键词和语义，显著优于单一检索。\t\n",
    "\n",
    "- 灵活性强：可通过融合策略和权重调整，适应不同业务场景。\n",
    "\n",
    "- 容错性好：关键词检索可部分弥补向量模型对拼写错误或罕见词的敏感性。\n",
    "\n",
    "**局限：**\n",
    "\n",
    "- 计算资源消耗大：需要同时维护和查询两套索引。\n",
    "\n",
    "- 参数调试复杂：融合权重等超参数需要反复实验调优。\n",
    "\n",
    "- 可解释性仍是挑战：融合后的结果排序理由难以直观分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dacf433",
   "metadata": {},
   "source": [
    "## 实践\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 正在连接到 Milvus: http://localhost:19530\n"
     ]
    }
   ],
   "source": [
    "# 连接 Milvus 数据库\n",
    "from pymilvus import connections\n",
    "\n",
    "MILVUS_URI = \"http://localhost:19530\" \n",
    "\n",
    "print(f\"--> 正在连接到 Milvus: {MILVUS_URI}\")\n",
    "connections.connect(uri=MILVUS_URI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc0ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 正在初始化 BGE-M3 嵌入模型...\n",
      "--> 嵌入模型初始化完成。密集向量维度: 1024\n"
     ]
    }
   ],
   "source": [
    "# 初始化嵌入模型\n",
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "print(\"--> 正在初始化 BGE-M3 嵌入模型...\")\n",
    "ef = BGEM3EmbeddingFunction(\n",
    "    model_name=\"models/bge/bge-m3\",  # 指向你下载的文件夹\n",
    "    device=\"cpu\",\n",
    "    use_fp16=False\n",
    ")\n",
    "print(f\"--> 嵌入模型初始化完成。密集向量维度: {ef.dim['dense']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 正在删除已存在的 Collection 'dragon_hybrid_demo'...\n",
      "--> 正在创建 Collection 'dragon_hybrid_demo'...\n",
      "--> Collection 创建成功。\n",
      "--> 正在为新集合创建索引...\n",
      "稀疏向量索引创建成功。\n",
      "密集向量索引创建成功。\n",
      "--> Collection 'dragon_hybrid_demo' 已加载到内存。\n"
     ]
    }
   ],
   "source": [
    "# 创建 Collection\n",
    "\n",
    "from pymilvus import MilvusClient, CollectionSchema, FieldSchema, DataType, Collection\n",
    "\n",
    "COLLECTION_NAME = \"dragon_hybrid_demo\"\n",
    "\n",
    "# 将旧的 Collection 删除\n",
    "milvus_client = MilvusClient(uri=MILVUS_URI)\n",
    "if milvus_client.has_collection(COLLECTION_NAME):\n",
    "    print(f\"--> 正在删除已存在的 Collection '{COLLECTION_NAME}'...\")\n",
    "    milvus_client.drop_collection(COLLECTION_NAME)\n",
    "    \n",
    "# 构建schema\n",
    "fields = [\n",
    "    # 自动生成唯一标识，避免主键冲突\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100),\n",
    "    # 7个VARCHAR字段用于存储元数据\n",
    "    FieldSchema(name=\"img_id\", dtype=DataType.VARCHAR, max_length=100),\n",
    "    FieldSchema(name=\"path\", dtype=DataType.VARCHAR, max_length=256),\n",
    "    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=256),\n",
    "    FieldSchema(name=\"description\", dtype=DataType.VARCHAR, max_length=4096),\n",
    "    FieldSchema(name=\"category\", dtype=DataType.VARCHAR, max_length=64),\n",
    "    FieldSchema(name=\"location\", dtype=DataType.VARCHAR, max_length=128),\n",
    "    FieldSchema(name=\"environment\", dtype=DataType.VARCHAR, max_length=64),\n",
    "    # 2个VECTOR字段用于存储向量表示\n",
    "    FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=ef.dim[\"dense\"])\n",
    "]\n",
    "\n",
    "# 如果集合不存在，则创建它及索引\n",
    "if not milvus_client.has_collection(COLLECTION_NAME):\n",
    "    print(f\"--> 正在创建 Collection '{COLLECTION_NAME}'...\")\n",
    "    schema = CollectionSchema(fields, description=\"关于龙的混合检索示例\")\n",
    "    # 创建集合\n",
    "    collection = Collection(name=COLLECTION_NAME, schema=schema, consistency_level=\"Strong\")\n",
    "    print(\"--> Collection 创建成功。\")\n",
    "\n",
    "    # 创建索引\n",
    "    print(\"--> 正在为新集合创建索引...\")\n",
    "    sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "    collection.create_index(\"sparse_vector\", sparse_index)\n",
    "    print(\"稀疏向量索引创建成功。\")\n",
    "\n",
    "    dense_index = {\"index_type\": \"AUTOINDEX\", \"metric_type\": \"IP\"}\n",
    "    collection.create_index(\"dense_vector\", dense_index)\n",
    "    print(\"密集向量索引创建成功。\")\n",
    "\n",
    "# 加载集合到内存\n",
    "collection = Collection(COLLECTION_NAME)\n",
    "collection.load()\n",
    "print(f\"--> Collection '{COLLECTION_NAME}' 已加载到内存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Collection 为空，开始插入数据...\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "import json\n",
    "\n",
    "DATA_PATH = \"data/dragon.json\"\n",
    "\n",
    "# 通过 is_empty 检查避免重复插入。\n",
    "if collection.is_empty:\n",
    "    print(f\"--> Collection 为空，开始插入数据...\")\n",
    "    with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    docs, metadata = [], []\n",
    "    for item in dataset:\n",
    "        parts = [\n",
    "            item.get('title', ''),\n",
    "            item.get('description', ''),\n",
    "            item.get('location', ''),\n",
    "            item.get('environment', ''),\n",
    "        ]\n",
    "        docs.append(' '.join(filter(None, parts)))\n",
    "        metadata.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 正在生成向量嵌入...\n",
      "--> 向量生成完成。\n"
     ]
    }
   ],
   "source": [
    "# 生成向量\n",
    "\n",
    "print(\"--> 正在生成向量嵌入...\")\n",
    "embeddings = ef(docs)\n",
    "print(\"--> 向量生成完成。\")\n",
    "\n",
    "# 获取两种向量\n",
    "sparse_vectors = embeddings[\"sparse\"]    # 稀疏向量：词频统计\n",
    "dense_vectors = embeddings[\"dense\"]      # 密集向量：语义编码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据插入 Collection 中\n",
    "\n",
    "# 为每个字段准备批量数据\n",
    "img_ids = [doc[\"img_id\"] for doc in metadata]\n",
    "paths = [doc[\"path\"] for doc in metadata]\n",
    "titles = [doc[\"title\"] for doc in metadata]\n",
    "descriptions = [doc[\"description\"] for doc in metadata]\n",
    "categories = [doc[\"category\"] for doc in metadata]\n",
    "locations = [doc[\"location\"] for doc in metadata]\n",
    "environments = [doc[\"environment\"] for doc in metadata]\n",
    "\n",
    "# 插入数据\n",
    "#  严格按照 Schema 定义的字段顺序插入，9个字段（7个标量+2个向量）\n",
    "collection.insert([\n",
    "    img_ids, paths, titles, descriptions, categories, locations, environments,\n",
    "    sparse_vectors, dense_vectors\n",
    "])\n",
    "# 强制将内存缓冲区数据写入磁盘，使数据立即可搜索\n",
    "collection.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb9386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 开始混合搜索 ====================\n",
      "查询: '悬崖上的巨龙'\n",
      "过滤器: 'category in [\"western_dragon\", \"chinese_dragon\", \"movie_character\"]'\n"
     ]
    }
   ],
   "source": [
    "# 生成 query 向量\n",
    "\n",
    "search_query = \"悬崖上的巨龙\"\n",
    "search_filter = 'category in [\"western_dragon\", \"chinese_dragon\", \"movie_character\"]'\n",
    "top_k = 5\n",
    "\n",
    "print(f\"\\n{'='*20} 开始混合搜索 {'='*20}\")\n",
    "print(f\"查询: '{search_query}'\")\n",
    "print(f\"过滤器: '{search_filter}'\")\n",
    "\n",
    "# 生成查询向量\n",
    "query_embeddings = ef([search_query])\n",
    "dense_vec = query_embeddings[\"dense\"][0]\n",
    "sparse_vec = query_embeddings[\"sparse\"]._getrow(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c1e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [单独] 密集向量搜索结果 ---\n",
      "1. 悬崖上的白龙 (Score: 0.7214)\n",
      "    路径: data/C3/dragon/dragon02.png\n",
      "    描述: 一头雄伟的白色巨龙栖息在悬崖边缘，背景是金色的云霞和远方的海岸。它拥有巨大的翅膀和优雅的身姿，是典型的西方奇幻生物。...\n",
      "2. 中华金龙 (Score: 0.5353)\n",
      "    路径: data/C3/dragon/dragon06.png\n",
      "    描述: 一条金色的中华龙在祥云间盘旋，它身形矫健，龙须飘逸，展现了东方神话中龙的威严与神圣。...\n",
      "3. 驯龙高手：无牙仔 (Score: 0.5231)\n",
      "    路径: data/C3/dragon/dragon05.png\n",
      "    描述: 在电影《驯龙高手》中，主角小嗝嗝骑着他的龙伙伴无牙仔在高空飞翔。他们飞向灿烂的太阳，下方是岛屿和海洋，画面充满了冒险与友谊。...\n",
      "\n",
      "--- [单独] 稀疏向量搜索结果 ---\n",
      "1. 悬崖上的白龙 (Score: 0.2254)\n",
      "    路径: data/C3/dragon/dragon02.png\n",
      "    描述: 一头雄伟的白色巨龙栖息在悬崖边缘，背景是金色的云霞和远方的海岸。它拥有巨大的翅膀和优雅的身姿，是典型的西方奇幻生物。...\n",
      "2. 中华金龙 (Score: 0.0857)\n",
      "    路径: data/C3/dragon/dragon06.png\n",
      "    描述: 一条金色的中华龙在祥云间盘旋，它身形矫健，龙须飘逸，展现了东方神话中龙的威严与神圣。...\n",
      "3. 驯龙高手：无牙仔 (Score: 0.0639)\n",
      "    路径: data/C3/dragon/dragon05.png\n",
      "    描述: 在电影《驯龙高手》中，主角小嗝嗝骑着他的龙伙伴无牙仔在高空飞翔。他们飞向灿烂的太阳，下方是岛屿和海洋，画面充满了冒险与友谊。...\n"
     ]
    }
   ],
   "source": [
    "# 分别进行单独检索\n",
    "\n",
    "# 定义搜索参数\n",
    "search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "\n",
    "# 先执行单独的搜索\n",
    "print(\"\\n--- [单独] 密集向量搜索结果 ---\")\n",
    "dense_results = collection.search(\n",
    "    [dense_vec],\n",
    "    anns_field=\"dense_vector\",\n",
    "    param=search_params,\n",
    "    limit=top_k,\n",
    "    expr=search_filter,\n",
    "    output_fields=[\"title\", \"path\", \"description\", \"category\", \"location\", \"environment\"]\n",
    ")[0]\n",
    "\n",
    "for i, hit in enumerate(dense_results):\n",
    "    print(f\"{i+1}. {hit.entity.get('title')} (Score: {hit.distance:.4f})\")\n",
    "    print(f\"    路径: {hit.entity.get('path')}\")\n",
    "    print(f\"    描述: {hit.entity.get('description')[:100]}...\")\n",
    "\n",
    "print(\"\\n--- [单独] 稀疏向量搜索结果 ---\")\n",
    "sparse_results = collection.search(\n",
    "    [sparse_vec],\n",
    "    anns_field=\"sparse_vector\",\n",
    "    param=search_params,\n",
    "    limit=top_k,\n",
    "    expr=search_filter,\n",
    "    output_fields=[\"title\", \"path\", \"description\", \"category\", \"location\", \"environment\"]\n",
    ")[0]\n",
    "\n",
    "for i, hit in enumerate(sparse_results):\n",
    "    print(f\"{i+1}. {hit.entity.get('title')} (Score: {hit.distance:.4f})\")\n",
    "    print(f\"    路径: {hit.entity.get('path')}\")\n",
    "    print(f\"    描述: {hit.entity.get('description')[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f335b51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 悬崖上的白龙 (Score: 0.0328)\n",
      "    路径: data/C3/dragon/dragon02.png\n",
      "    描述: 一头雄伟的白色巨龙栖息在悬崖边缘，背景是金色的云霞和远方的海岸。它拥有巨大的翅膀和优雅的身姿，是典型的西方奇幻生物。...\n",
      "2. 中华金龙 (Score: 0.0320)\n",
      "    路径: data/C3/dragon/dragon06.png\n",
      "    描述: 一条金色的中华龙在祥云间盘旋，它身形矫健，龙须飘逸，展现了东方神话中龙的威严与神圣。...\n",
      "3. 奔跑的奶龙 (Score: 0.0315)\n",
      "    路径: data/C3/dragon/dragon04.png\n",
      "    描述: 一只Q版的黄色小恐龙，有着大大的绿色眼睛和友善的微笑。是一部动画中的角色，非常可爱。...\n",
      "4. 驯龙高手：无牙仔 (Score: 0.0313)\n",
      "    路径: data/C3/dragon/dragon05.png\n",
      "    描述: 在电影《驯龙高手》中，主角小嗝嗝骑着他的龙伙伴无牙仔在高空飞翔。他们飞向灿烂的太阳，下方是岛屿和海洋，画面充满了冒险与友谊。...\n",
      "5. 霸王龙的怒吼 (Score: 0.0312)\n",
      "    路径: data/C3/dragon/dragon03.png\n",
      "    描述: 史前时代的霸王龙张开血盆大口，发出震天的怒吼。在它身后，几只翼龙在阴沉的天空中盘旋，展现了白垩纪的原始力量。...\n"
     ]
    }
   ],
   "source": [
    "# 使用 RRF 进行混合检索\n",
    "from pymilvus import RRFRanker, AnnSearchRequest\n",
    "\n",
    "rerank = RRFRanker(k=60)\n",
    "\n",
    "# 创建搜索请求\n",
    "dense_req = AnnSearchRequest([dense_vec], \"dense_vector\", search_params, limit=top_k)\n",
    "sparse_req = AnnSearchRequest([sparse_vec], \"sparse_vector\", search_params, limit=top_k)\n",
    "\n",
    "# 执行混合搜索\n",
    "results = collection.hybrid_search(\n",
    "    [sparse_req, dense_req],\n",
    "    rerank=rerank,\n",
    "    limit=top_k,\n",
    "    output_fields=[\"title\", \"path\", \"description\", \"category\", \"location\", \"environment\"]\n",
    ")[0]\n",
    "\n",
    "# 打印最终结果\n",
    "for i, hit in enumerate(results):\n",
    "    print(f\"{i+1}. {hit.entity.get('title')} (Score: {hit.distance:.4f})\")\n",
    "    print(f\"    路径: {hit.entity.get('path')}\")\n",
    "    print(f\"    描述: {hit.entity.get('description')[:100]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
