{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1451d5",
   "metadata": {},
   "source": [
    "# 语言模型的监督式微调（Supervised Fine-Tuning, SFT）\n",
    "\n",
    "SFT 是一种把通用语言模型转换成任务型助手的方法。\n",
    "\n",
    "通过训练 提示与理想回应的成对 数据，使模型学会模仿示例中的回答，从而能够按照指令行事、展示期望的行为并正确调用工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea4e22",
   "metadata": {},
   "source": [
    "SFT 训练流程如下：\n",
    "1. 基础模型：一个未经调整的 LLM 。\n",
    "\n",
    "2. 带标签的数据集：收集并整理用户提示与理想助理回应的配对。\n",
    "\n",
    "3. SFT训练：通过配对数据集对模型进行微调，利用最小化回应的交叉熵损失来训练模型。\n",
    "\n",
    "    $$\\mathcal{L}_{\\text{SFT}} = -\\sum_{i=1}^N \\log \\bigl(p_\\theta(\\text{Response}(i)\\mid \\text{Prompt}(i))\\bigr)$$\n",
    "\n",
    "    交叉熵损失函数会惩罚偏离标签回应的输出，因此 SFT 本质上是在教模型“模仿”。\n",
    "\n",
    "4. 微调后的模型：进过训练后，模型可以针对新的查询给出合适的回复。\n",
    "\n",
    "![SFT.png](images/SFT.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a52d71",
   "metadata": {},
   "source": [
    "## SFT 使用场景\n",
    "\n",
    "- 激发新的模型行为\n",
    "\n",
    "    - 将预训练模型转变为能遵循指令的助理。\n",
    "\n",
    "    - 让不具备推理能力的模型学会基本推理。\n",
    "\n",
    "    - 让模型在没有明确说明的情况下使用特定工具。\n",
    "\n",
    "- 激发模型能力\n",
    "\n",
    "    - 利用强大的大模型**生成高质量的合成数据**，通过训练把这些能力“蒸馏”到小模型中。\n",
    "\n",
    "当你需要模型快速适应新行为且有示例数据时，SFT 往往是正确的选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d8c08",
   "metadata": {},
   "source": [
    "## SFT 数据策划原则\n",
    "\n",
    "SFT 的效果依赖于数据质量，优秀的数据能让模型学习到更有用的行为。\n",
    "\n",
    "常用的数据策划方法为：\n",
    "\n",
    "- 蒸馏：用更强的指令模型生成回复，再训练小模型去模仿这些回复，把强模型的能力迁移到弱模型上。\n",
    "\n",
    "- Best‑of‑K / 拒绝采样：针对同一提示生成多个候选回复，再用奖励函数选出最好的作为训练数据。\n",
    "\n",
    "- 过滤：从大型 SFT 数据集中挑选出回应质量高且提示多样性好的样本，形成精简的高质量数据集。\n",
    "\n",
    "SFT 会迫使模型模仿它所见到的一切——包括糟糕的回答。\n",
    "\n",
    "所以数据策划的核心是**质量比数量重要**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec21be0",
   "metadata": {},
   "source": [
    "## SFT 微调方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56fa866",
   "metadata": {},
   "source": [
    "### 全参数微调\n",
    "\n",
    "对模型的每一层权重加入一个完整的权重更新矩阵 $\\Delta W$。\n",
    "\n",
    "这种方法修改了整个模型的参数，可以显著提高性能，但也增加了计算量。\n",
    "\n",
    "![SFT-full-fine-tuning.png](images/SFT-full-fine-tuning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0cea11",
   "metadata": {},
   "source": [
    "### 参数高效微调（PEFT）\n",
    "\n",
    "参数高效微调通过在每层引入小的低秩矩阵 A 和 B 来调整模型参数。\n",
    "\n",
    "这种方法减少了可训练参数的数量，节省显存，缺点是学习和遗忘都更有限，因为更新的参数更少。\n",
    "\n",
    "![SFT-PEFT.png](images/SFT-PEFT.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e840f",
   "metadata": {},
   "source": [
    "# 实践 SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db055c",
   "metadata": {},
   "source": [
    "## 环境配置\n",
    "\n",
    "创建虚拟环境：conda create --prefix=F:env/posttraining python=3.12\n",
    "\n",
    "安装pytorch：pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "安装其他包：pip install numpy==1.26.4 transformers==4.52.4 huggingface-hub==0.33.0 datasets==2.21 trl==0.14.0 jinja2==3.1.2 markupsafe==2.0.1 tabulate==0.9.0 pandas==2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab895d0",
   "metadata": {},
   "source": [
    "## 导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c76ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\env\\posttraining\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM, SFTConfig\n",
    "\n",
    "# 过滤 warning\n",
    "import warnings\n",
    "from tqdm import TqdmWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca199b65",
   "metadata": {},
   "source": [
    "## 定义函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71f754",
   "metadata": {},
   "source": [
    "### 模型回复函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44dce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "生成模型对用户输入的回复\n",
    "\n",
    "args:\n",
    "    model: 模型\n",
    "    tokenizer: 分词器\n",
    "    user_message: 用户消息，用户的输入\n",
    "    system_message: 系统消息，可以用于设置模型的行为\n",
    "    max_new_tokens: 生成回复的最大新 token 数，默认值为 100\n",
    "\n",
    "return:\n",
    "    模型生成的回复\n",
    "\"\"\"\n",
    "def generate_responses(model, tokenizer, user_message, system_message=None, max_new_tokens=100):\n",
    "    \n",
    "    # 构建消息列表（列表内的所有消息最后都会被模型“看到“）\n",
    "    messages = []\n",
    "    \n",
    "    # 将系统消息添加到消息列表中\n",
    "    if system_message:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    # 将用户消息添加到消息列表中\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    # 调用分词器的 apply_chat_template 方法，将消息列表转换为模型能理解的 prompt\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False,\n",
    "    )\n",
    "\n",
    "    # 将 prompt 转换为模型可接受的输入张量\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # 模型生成回复\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id, \n",
    "        )\n",
    "    \n",
    "    # 获取 prompt 长度\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    # 切片，只保留模型生成的部分\n",
    "    generated_ids = outputs[0][input_len:]\n",
    "    # 解码为可读文本\n",
    "    response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb346a",
   "metadata": {},
   "source": [
    "### 模型回复测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e4bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "测试模型生成效果\n",
    "\n",
    "args:\n",
    "    model: 模型\n",
    "    tokenizer: 分词器\n",
    "    questions: 测试问题列表\n",
    "    system_message: 系统消息，可以用于设置模型的行为\n",
    "    title: 测试标题，默认值为 \"Model Output\"\n",
    "\n",
    "return:\n",
    "    无\n",
    "\"\"\"\n",
    "def test_model_with_questions(model, tokenizer, questions, system_message=None, title=\"Model Output\"):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        response = generate_responses(model, tokenizer, question, system_message)\n",
    "        print(f\"\\nModel Input {i}:\\n{question}\\nModel Output {i}:\\n{response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4647bd92",
   "metadata": {},
   "source": [
    "### 加载模型和分词器函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6629eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "加载模型和分词器\n",
    "\n",
    "args:\n",
    "    model_name_or_path: 模型名称或路径（使用本地模型）\n",
    "    use_gpu: 是否使用 GPU，默认值为 False\n",
    "\n",
    "return:\n",
    "    model: 加载好的模型\n",
    "    tokenizer: 加载好的分词器\n",
    "\"\"\"\n",
    "def load_model_and_tokenizer(model_name_or_path, use_gpu=False):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "    if use_gpu:\n",
    "        model = model.to(\"cuda\")\n",
    "\n",
    "    # 设置默认的聊天模板\n",
    "    if not tokenizer.chat_template:\n",
    "        tokenizer.chat_template = \"\"\"{% for message in messages %}\n",
    "                {% if message['role'] == 'system' %}System: {{ message['content'] }}\\n\n",
    "                {% elif message['role'] == 'user' %}User: {{ message['content'] }}\\n\n",
    "                {% elif message['role'] == 'assistant' %}Assistant: {{ message['content'] }} \n",
    "                {% endif %}\n",
    "                {% endfor %}\"\"\"\n",
    "\n",
    "    # 设置 pad_token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f194e5",
   "metadata": {},
   "source": [
    "### 数据集可视化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9bec382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "可视化数据集\n",
    "\n",
    "参数:\n",
    "    dataset: 要可视化的数据集\n",
    "\n",
    "返回:\n",
    "    None\n",
    "\"\"\"\n",
    "def display_dataset(dataset):\n",
    "    rows = []\n",
    "    for i in range(3):\n",
    "        example = dataset[i]\n",
    "        user_msg = next(m['content'] for m in example['messages'] if m['role'] == 'user')\n",
    "        assistant_msg = next(m['content'] for m in example['messages'] if m['role'] == 'assistant')\n",
    "        rows.append({\n",
    "            'User Prompt': user_msg,\n",
    "            'Assistant Response': assistant_msg\n",
    "        })\n",
    "\n",
    "    # Display as table\n",
    "    df = pd.DataFrame(rows)\n",
    "    pd.set_option('display.max_colwidth', None)  # Avoid truncating long strings\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e3aad",
   "metadata": {},
   "source": [
    "## 加载 Qwen3-0.6B 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d193019",
   "metadata": {},
   "source": [
    "国内下载网站：https://www.modelscope.cn/models/Qwen/Qwen3-0.6B/files\n",
    "\n",
    "![Qwen3-0.6B](images/Qwen-0.6B.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495f13f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Base Model (Before SFT) Output ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\env\\posttraining\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Input 1:\n",
      "Give me an 1-sentence introduction of LLM.\n",
      "Model Output 1:\n",
      "A large language model is a system designed to understand and generate human language.\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Calculate 1+1-1\n",
      "Model Output 2:\n",
      "The expression $1 + 1 - 1$ can be evaluated step by step:\n",
      "\n",
      "1. Add the first two 1s:  \n",
      "   $1 + 1 = 2$\n",
      "\n",
      "2. Subtract the third 1:  \n",
      "   $2 - 1 = 1$\n",
      "\n",
      "So, the final result is:  \n",
      "**1**.\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "What's the difference between thread and process?\n",
      "Model Output 3:\n",
      "The difference between **thread** and **process** is important in operating systems and concurrent programming. Here's a clear breakdown:\n",
      "\n",
      "### 1. **Process**:\n",
      "- A **process** is a **thread** that is running independently.\n",
      "- It is a **unit of execution** in a program.\n",
      "- Processes are managed by the operating system and can be created, stopped, or terminated.\n",
      "- Processes are isolated from other processes, meaning they share the same memory space and resources.\n",
      "- Example:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "# 加载模型和分词器\n",
    "model, tokenizer = load_model_and_tokenizer(\"Qwen-0.6B\", USE_GPU)\n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"Give me an 1-sentence introduction of LLM.\",\n",
    "    \"Calculate 1+1-1\",\n",
    "    \"What's the difference between thread and process?\"\n",
    "]\n",
    "# 测试模型回复\n",
    "test_model_with_questions(model, tokenizer, questions, title=\"Base Model (Before SFT) Output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd8fe58",
   "metadata": {},
   "source": [
    "从问题2和3可以看出，模型生成的回复并不理想，有些许杂乱。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0163e3",
   "metadata": {},
   "source": [
    "## 加载 SFT 数据集\n",
    "\n",
    "数据集下载路径：https://hf-mirror.com/datasets/banghua/DL-SFT-Dataset/tree/main/data\n",
    "\n",
    "![DL-SFT-Dataset](images/DL-SFT-Dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf2d7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Prompt</th>\n",
       "      <th>Assistant Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- The left child should have a value less than the parent node's value, and the right child should have a value greater than the parent node's value.</td>\n",
       "      <td>This statement is correct. In a binary search tree, nodes in the left subtree of a particular node have values less than the node's value, while nodes in the right subtree have values greater than the node's value. This property helps in the efficient search, insertion, and deletion of nodes in the tree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To pass three levels must be the plan.\\nThen tackle Two, when that is done.\\nOf 100 that start, at the end will be 20.\\nFinQuiz is a website that helps you prepare.\\nUse it to be stress-free, and not lose your hair.\\nThen, take the exam with a smile on your face.\\nBe confident that you will gain your place.\\nSo make this the goal to which you aspire. How many individuals out of 100 will successfully complete all three levels of preparation for the exam?</td>\n",
       "      <td>Based on the given information, out of 100 individuals who start, only 20 will make it to the end. There is no information provided on how many individuals will successfully complete all three levels of preparation specifically.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you translate the text material into Spanish or any other language?: He really is, you know.\\nThings a hero should show.\\nHe loves me more than a zillion things.\\nHe loves me when I sing my jolly folktale rhymes.\\nHe's good, not just good, in fact he's great!\\nBut because he's my best mate!\\nWOW !!! I love it!!!!</td>\n",
       "      <td>¿Puede traducir el texto a español o a cualquier otro idioma?: \\nRealmente lo es, ya sabes.\\nCosas que un héroe debería demostrar.\\nMe quiere más que un millón de cosas.\\nMe quiere cuando canto mis alegres rimas de cuentos populares.\\nEs bueno, no solo bueno, ¡de hecho es genial!\\n¡Pero porque es mi mejor amigo!\\n¡WOW! ¡Me encanta!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                 User Prompt  \\\n",
       "0                                                                                                                                                                                                                                                                                                                      - The left child should have a value less than the parent node's value, and the right child should have a value greater than the parent node's value.   \n",
       "1  To pass three levels must be the plan.\\nThen tackle Two, when that is done.\\nOf 100 that start, at the end will be 20.\\nFinQuiz is a website that helps you prepare.\\nUse it to be stress-free, and not lose your hair.\\nThen, take the exam with a smile on your face.\\nBe confident that you will gain your place.\\nSo make this the goal to which you aspire. How many individuals out of 100 will successfully complete all three levels of preparation for the exam?   \n",
       "2                                                                                                                                             Can you translate the text material into Spanish or any other language?: He really is, you know.\\nThings a hero should show.\\nHe loves me more than a zillion things.\\nHe loves me when I sing my jolly folktale rhymes.\\nHe's good, not just good, in fact he's great!\\nBut because he's my best mate!\\nWOW !!! I love it!!!!   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              Assistant Response  \n",
       "0                              This statement is correct. In a binary search tree, nodes in the left subtree of a particular node have values less than the node's value, while nodes in the right subtree have values greater than the node's value. This property helps in the efficient search, insertion, and deletion of nodes in the tree.  \n",
       "1                                                                                                           Based on the given information, out of 100 individuals who start, only 20 will make it to the end. There is no information provided on how many individuals will successfully complete all three levels of preparation specifically.  \n",
       "2  ¿Puede traducir el texto a español o a cualquier otro idioma?: \\nRealmente lo es, ya sabes.\\nCosas que un héroe debería demostrar.\\nMe quiere más que un millón de cosas.\\nMe quiere cuando canto mis alegres rimas de cuentos populares.\\nEs bueno, no solo bueno, ¡de hecho es genial!\\n¡Pero porque es mi mejor amigo!\\n¡WOW! ¡Me encanta!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载数据集\n",
    "train_dataset = load_dataset(\"parquet\", data_files=\"DL-SFT-Dataset/train-00000-of-00001.parquet\")[\"train\"]\n",
    "\n",
    "if not USE_GPU:\n",
    "    train_dataset = train_dataset.select(range(100))\n",
    "\n",
    "display_dataset(train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb5625",
   "metadata": {},
   "source": [
    "## 使用 SFT 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69541bd",
   "metadata": {},
   "source": [
    "### 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee694489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFTTrainer 设置\n",
    "sft_config = SFTConfig(\n",
    "    learning_rate=8e-5, # 学习率，SFT常用较小学习率，以避免破坏预训练获得的知识。\n",
    "    num_train_epochs=1, # 训练轮数，SFT常用较小轮数，以避免过拟合。\n",
    "    per_device_train_batch_size=1, # 每块 GPU 的 batch size。\n",
    "    gradient_accumulation_steps=8, # 梯度累积次数，实现在不增加显存的情况下模拟更大 batch。\n",
    "    gradient_checkpointing=False, # 不启用梯度检查点。\n",
    "    logging_steps=2,  # 每两个 step 打印一次 log。\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6696db",
   "metadata": {},
   "source": [
    "### 创建并启动训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a7df3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='371' max='371' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [371/371 08:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.647700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.548500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.354900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.195300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.640100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.456200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.050300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.405100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.304500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.306800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.135800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.163900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.968200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>2.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>2.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>2.122500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>2.320600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>2.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.957900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>2.270700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>2.471600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>2.115400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>2.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>2.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>2.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.286400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>2.414900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>2.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>2.244600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>2.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>2.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>2.192200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>2.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.935100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>2.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>2.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>2.344900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>2.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>2.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.993700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>2.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>2.530100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>1.907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>2.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.902800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>1.892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>2.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.913300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>2.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>2.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>2.355500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>2.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>2.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>2.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>2.359800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>2.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>2.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.991100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>2.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>2.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>2.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>2.307900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>2.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>2.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>2.553800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>2.281100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>2.176700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>2.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.667300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>2.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1.911700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>1.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>1.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>2.090100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.854600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>2.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>2.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>2.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>1.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>2.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>2.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.934900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>2.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>2.212400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>2.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>2.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.909100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>2.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>1.963100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>2.192900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>1.733700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>2.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>1.585700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>2.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>1.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>2.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>2.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>1.775300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>2.179100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.754000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>2.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>1.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>2.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>2.393800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>2.279400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>2.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>2.078700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>1.713800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.710400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>2.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>1.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>2.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>2.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>2.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>2.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>2.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>1.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>1.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>2.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>1.840700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>1.945100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.975400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>1.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>1.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>2.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>2.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>1.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>1.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>1.836100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>2.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>2.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>2.204200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>1.950500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>2.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>1.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>2.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>1.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>1.937900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.918200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=371, training_loss=2.1162383318590026, metrics={'train_runtime': 531.8997, 'train_samples_per_second': 5.567, 'train_steps_per_second': 0.697, 'total_flos': 1255369248866304.0, 'train_loss': 2.1162383318590026, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_trainer = SFTTrainer(\n",
    "    model=model, # 要训练的模型\n",
    "    args=sft_config, # 训练配置\n",
    "    train_dataset=train_dataset, # 训练数据集\n",
    "    processing_class=tokenizer, # 用于处理文本的分词器\n",
    ")\n",
    "sft_trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8da49",
   "metadata": {},
   "source": [
    "## SFT 后的模型回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12cd695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Base Model (After SFT) Output ===\n",
      "\n",
      "Model Input 1:\n",
      "Give me an 1-sentence introduction of LLM.\n",
      "Model Output 1:\n",
      "I am not capable of creating a specific introduction for a llm. However, I can provide a general introduction for a llm that is designed to assist users in various tasks, such as language processing, natural language generation, and information retrieval.\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Calculate 1+1-1\n",
      "Model Output 2:\n",
      "1+1-1 = 1.\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "What's the difference between thread and process?\n",
      "Model Output 3:\n",
      "A thread is a lightweight process that runs within a single program or application. It is a separate instance of the same program or application that can be controlled independently from the main program or application. Threads are created by the operating system when a program or application starts executing, and they are responsible for handling user input and output. \n",
      "\n",
      "On the other hand, a process is a separate instance of a program or application that is independent from the main program or application. A process is a larger unit that consists of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not USE_GPU:\n",
    "    sft_trainer.model.to(\"cpu\")\n",
    "test_model_with_questions(sft_trainer.model, tokenizer, questions,\n",
    "                          title=\"Base Model (After SFT) Output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cbe8b",
   "metadata": {},
   "source": [
    "通过 SFT 后，可以明显的看到，问题2和3的回复都发生了好的变化，符合我们的预期。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1339e8e5",
   "metadata": {},
   "source": [
    "## 保存模型\n",
    "\n",
    "保存微调后的模型权重（pytorch_model.bin 或 model.safetensors）和配置文件（config.json）\n",
    "\n",
    "![Qwen-0.6B-SFT](images/Qwen-0.6B-SFT.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存至: Qwen-0.6B-SFT\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"Qwen-0.6B-SFT\"\n",
    "sft_trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"模型已保存至: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
